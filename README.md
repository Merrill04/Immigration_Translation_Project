# Immigration Translator Offline

A completely offline speech-to-speech translation system for Hindi â†” English, built with Python 3.10+, FastAPI, and local AI models. No Docker, no cloud services, no network required at runtime.

## ğŸŒŸ Features

- **Speech-to-Speech Translation**: Hindi â†” English bidirectional translation
- **Completely Offline**: All models run locally, no internet required
- **Modern Web Interface**: Clean, responsive HTML/JS frontend with MediaRecorder
- **Multiple TTS Backends**: Piper TTS and XTTS v2 support
- **Optimized Performance**: Uses int8 quantization and efficient models
- **Cross-Platform**: Windows batch script and Linux/macOS shell script

## ğŸ—ï¸ Architecture

- **Backend**: FastAPI with REST endpoints
- **ASR**: faster-whisper with CTranslate2 (whisper-small-ct2)
- **MT**: Facebook NLLB-200-distilled-600M via Transformers
- **TTS**: Piper TTS (default) or XTTS v2 (configurable)
- **Frontend**: Minimal HTML/JS with MediaRecorder API

## ğŸ“‹ Requirements

- **Python**: 3.10 or higher
- **RAM**: 8GB+ recommended (4GB minimum)
- **Storage**: 5GB+ for models
- **GPU**: Optional but recommended (4GB+ VRAM for GPU acceleration)

## ğŸš€ Quick Start

### Windows

1. **Clone/Download** the project folder
2. **Run the batch script**:
   ```cmd
   run.bat
   ```
3. **Open browser** to `http://localhost:8000`

### Linux/macOS

1. **Clone/Download** the project folder
2. **Make script executable**:
   ```bash
   chmod +x run.sh
   ```
3. **Run the shell script**:
   ```bash
   ./run.sh
   ```
4. **Open browser** to `http://localhost:8000`

The scripts will automatically:
- Create a virtual environment
- Install dependencies
- Download models (if not present)
- Start the server

## ğŸ“ Project Structure

```
immigration_translator_offline/
â”œâ”€â”€ app/                    # FastAPI backend
â”‚   â”œâ”€â”€ main.py            # Main FastAPI app
â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”œâ”€â”€ asr.py             # Speech recognition backend
â”‚   â”œâ”€â”€ mt.py              # Machine translation backend
â”‚   â””â”€â”€ tts.py             # Text-to-speech backend
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.json        # Configuration file
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_models.py # Model download script
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html         # Web frontend
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_app.py        # Unit tests
â”œâ”€â”€ models/                # AI models (created by download script)
â”œâ”€â”€ voices/                # TTS voice files
â”œâ”€â”€ samples/               # Test audio samples
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ run.bat               # Windows startup script
â”œâ”€â”€ run.sh                # Linux/macOS startup script
â””â”€â”€ README.md             # This file
```

## ğŸ”§ Manual Setup

If you prefer manual setup or the scripts don't work:

### 1. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Download Models

```bash
python scripts/download_models.py
```

### 4. Set Offline Environment Variables

```bash
# Windows
set HF_HUB_OFFLINE=1
set TRANSFORMERS_OFFLINE=1

# Linux/macOS
export HF_HUB_OFFLINE=1
export TRANSFORMERS_OFFLINE=1
```

### 5. Start the Server

```bash
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ›ï¸ Configuration

Edit `config/config.json` to customize:

```json
{
  "mode": "offline",
  "languages": ["en", "hi"],
  "src_lang_code": "eng_Latn",
  "tgt_lang_code": "hin_Deva",
  "tts_backend": "piper",
  "asr_model_path": "./models/whisper-small-ct2",
  "mt_model_path": "./models/nllb-200-distilled-600M",
  "piper_voice_hi": "./voices/hi-IN.onnx",
  "piper_voice_en": "./voices/en-US.onnx",
  "device": "auto",
  "compute_type": "int8",
  "beam_size": 1,
  "chunk_length": 30,
  "enable_vad": true,
  "mt_device": "auto",
  "tts_device": "cpu"
}
```

### Key Settings

- **`device`**: `"auto"`, `"cpu"`, or `"cuda"`
- **`compute_type`**: `"int8"`, `"int8_float16"`, or `"float16"`
- **`tts_backend`**: `"piper"` or `"xtts"`
- **`mt_device`**: Force MT to CPU if GPU memory is limited

## ğŸ”Œ API Endpoints

- **`GET /health`** - Health check and backend status
- **`GET /config`** - Get current configuration
- **`POST /config`** - Update configuration
- **`POST /asr`** - Transcribe audio file
- **`POST /asr/chunk`** - Transcribe audio chunk (streaming)
- **`POST /translate`** - Translate text
- **`POST /tts`** - Synthesize speech
- **`GET /`** - Serve web frontend

```


